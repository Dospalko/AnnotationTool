```py
import json
label_names = ['LESSOR', 'LESSEE']

def csv_result():
    return {
        "document": -1,
        "id": 0,
        "tokens": [],
        "ner_tags": []
    }

def correct_ner_tags(tags):
    n = len(tags)
    if n < 2:
        return tags

    i = 0
    while i < n - 1:
        if tags[i] == 0:
            if tags[i + 1] == 2:
                tags[i + 1] = 1
                # Change all subsequent numbers to 2 until a 0 is found
                j = i + 2
                while j < n and (tags[j] == 1 or tags[j] == 2):
                    tags[j] = 2
                    j += 1
                i = j - 1  # Move index forward to continue after the changed sequence

            elif tags[i + 1] == 4:
                tags[i + 1] = 3
                j = i + 2
                while j < n  and (tags[j] == 3 or tags[j] == 4):
                    tags[j] = 4
                    j += 1
                i = j - 1  # Move index forward to continue after the changed sequence

        i += 1

    return tags

def convert_to_csv(filename):
    result_string_list = []

    with open(filename, mode='r', encoding='utf-8') as file:
        for row in file:
            line = json.loads(row)
            text = line['text']  # Keeping the text with leading and internal spaces
            result = csv_result()
            result['document'] = line['id']
            result['id'] = 1  # Assuming the whole text is a single document

            words_with_positions = []
            start = 0
            i = 0
            while i < len(text):
                if text[i].isspace():
                    start = i + 1  # Move start past the space
                else:
                    end = i
                    while end < len(text) and not text[end].isspace():
                        end += 1
                    word = text[i:end]
                    words_with_positions.append((word, i, end, 0))  # Store position from the first non-space character
                    i = end  # Set i to the last processed character (space or end of word)
                i += 1

            result['tokens'] = words_with_positions
            result['ner_tags'] = [0] * len(result['tokens'])

            # Apply NER tags based on the 'label' data
            for idx, (word, pos_start, pos_end, _) in enumerate(words_with_positions):
                for l_start, l_end, tag in line['label']:
                    if pos_start >= l_start and pos_end <= l_end:
                        t_index = label_names.index(tag)
                        if pos_start == l_start:
                            ner_tag = 1 + 2 * t_index  # Start tags as 1, 3, ...
                        else:
                            ner_tag = 2 + 2 * t_index  # Inside tags as 2, 4, ...
                        result['ner_tags'][idx] = ner_tag

            # Prepare output
            tok_string = [t[0] for t in result['tokens']]
            ner_tags_string = correct_ner_tags(result['ner_tags'])
            r_string = {'document': result["document"], 'id': result["id"], 'tokens': tok_string, 'ner_tags': ner_tags_string}
            result_string_list.append(r_string)

    return result_string_list

input_file = "/content/drive/MyDrive/diplomka-Tatiana/data/dataset_labeled/dataset_manual_labeled_ner_emph.jsonl"

string_list = convert_to_csv(input_file)
```